{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "import sys\n",
    "\n",
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "from imageio import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_name,domain,batch_size=1,is_val=False):\n",
    "    data_type = \"train%s\"%domain if not is_val else \"test%s\"%domain\n",
    "    path = glob('../input/%s/%s/%s/*' % (dataset_name,dataset_name,data_type))\n",
    "    batch_images = np.random.choice(path, size=batch_size)\n",
    "    img_res = (128,128)\n",
    "    imgs = []\n",
    "    for img_path in batch_images:\n",
    "        img = imread(img_path)\n",
    "        if not is_val:\n",
    "            img = transform.resize(img,img_res)\n",
    "            if np.random.random() > 0.5:\n",
    "                img = np.fliplr(img)\n",
    "        else:\n",
    "            img = transform.resize(img,img_res)\n",
    "            imgs.append(img)\n",
    "    imgs = np.array(imgs)/127.5 - 1.\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(dataset_name,batch_size=1, is_val=False):\n",
    "    data_type = \"train\" if not is_val else \"val\"\n",
    "    path_A = glob('../input/%s/%s/%sA/*' % (dataset_name,dataset_name, data_type))\n",
    "    path_B = glob('../input/%s/%s/%sB/*' % (dataset_name,dataset_name, data_type))\n",
    "    global n_batches\n",
    "    n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
    "    total_samples = n_batches * batch_size\n",
    "    path_A = np.random.choice(path_A, total_samples, replace=False)\n",
    "    path_B = np.random.choice(path_B, total_samples, replace=False)\n",
    "    img_res = (128,128)\n",
    "    for i in range(n_batches-1):\n",
    "        batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
    "        batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
    "        imgs_A, imgs_B = [], []\n",
    "        for img_A, img_B in zip(batch_A, batch_B):\n",
    "            img_A = imread(img_A)\n",
    "            img_B = imread(img_B)\n",
    "            img_A = transform.resize(img_A, img_res)\n",
    "            img_B = transform.resize(img_B, img_res)\n",
    "            if not is_val and np.random.random() > 0.5:\n",
    "                img_A = np.fliplr(img_A)\n",
    "                img_B = np.fliplr(img_B)\n",
    "            imgs_A.append(img_A)\n",
    "            imgs_B.append(img_B)\n",
    "        imgs_A = np.array(imgs_A)/127.5 - 1.\n",
    "        imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "        yield imgs_A, imgs_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "def imread(path):\n",
    "    return imageio.imread(path).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    #Taking advantage of U-net shape--good for sizes convolution \n",
    "    def conv2d(layer_input,filters,f_size=4,bn=True):\n",
    "        #layers for downsampling\n",
    "        d = Conv2D(filters,kernel_size=f_size,strides=2,padding=\"same\")(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        #use leakyrelu as activation funcion\n",
    "        if bn:\n",
    "            d = InstanceNormalization()(d)\n",
    "        return d\n",
    "    def deconv2d(layer_input,skip_input,filters,f_size=4,dropout_rate=0):\n",
    "        #layers for upsampling\n",
    "        u = UpSampling2D(size=2)(layer_input)\n",
    "        u = Conv2D(filters,kernel_size=f_size,strides=1,padding='same',activation='relu')(u)\n",
    "        if dropout_rate:\n",
    "            u = Dropout(dropout_rate)(u)\n",
    "        u = InstanceNormalization()(u)\n",
    "        u = Concatenate()([u,skip_input])\n",
    "        #to skip connect\n",
    "        return u\n",
    "    \n",
    "    d0 = Input(shape=img_shape)\n",
    "    #downsampling layers\n",
    "    d1 = conv2d(d0, gf, bn=False)\n",
    "    d2 = conv2d(d1,gf*2)\n",
    "    d3 = conv2d(d2,gf*4)\n",
    "    d4 = conv2d(d3,gf*8)\n",
    "    d5 = conv2d(d4,gf*8)\n",
    "    d6 = conv2d(d5,gf*8)\n",
    "    d7 = conv2d(d6,gf*8)\n",
    "    #upsampling deconvolution layers\n",
    "    u1 = deconv2d(d7,d6,gf*8)\n",
    "    u2 = deconv2d(u1,d5,gf*8)\n",
    "    u3 = deconv2d(u2,d4,gf*8)\n",
    "    u4 = deconv2d(u3,d3,gf*4)\n",
    "    u5 = deconv2d(u4,d2,gf*2)\n",
    "    u6 = deconv2d(u5,d1,gf)\n",
    "    u7 = UpSampling2D(size=2)(u6)\n",
    "    output_img = Conv2D(channels,kernel_size=4,strides=1,padding='same',activation='tanh')(u7)\n",
    "    return Model(d0,output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(build_generator().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    def d_layer(layer_input,filters,f_size=4,bn=True):\n",
    "        d = Conv2D(filters,kernel_size=f_size,strides=2,padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if bn:\n",
    "            d = InstanceNormalization()(d)\n",
    "        return d\n",
    "    \n",
    "    img = Input(shape=img_shape)\n",
    "    d1 = d_layer(img,df,bn=False)\n",
    "    d2 = d_layer(d1,df*2)\n",
    "    d3 = d_layer(d2,df*4)\n",
    "    d4 = d_layer(d3,df*8)\n",
    "    validity = Conv2D(1,kernel_size=4,strides=1,padding='same')(d4)\n",
    "    return Model(img,validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset_name,epochs, batch_size=128, sample_interval=50):\n",
    "        start_time = datetime.datetime.now()\n",
    "        global n_batches\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + disc_patch)\n",
    "        fake = np.zeros((batch_size,) + disc_patch)\n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(load_batch(dataset_name,batch_size)):\n",
    "                #  Train Discriminators\n",
    "                # Translate images to opposite domain\n",
    "                fake_B = g_AB.predict(imgs_A)\n",
    "                fake_A = g_BA.predict(imgs_B)\n",
    "                # Train the discriminators (original images = real / translated = Fake)\n",
    "                dA_loss_real = d_A.train_on_batch(imgs_A, valid)\n",
    "                dA_loss_fake = d_A.train_on_batch(fake_A, fake)\n",
    "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "                dB_loss_real = d_B.train_on_batch(imgs_B, valid)\n",
    "                dB_loss_fake = d_B.train_on_batch(fake_B, fake)\n",
    "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "                # Total disciminator loss\n",
    "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
    "                # Train the generators\n",
    "                g_loss = combined.train_on_batch([imgs_A, imgs_B], [valid, valid, \\\n",
    "                                                                         imgs_B, imgs_A, \\\n",
    "                                                                         imgs_A, imgs_B])\n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "                # Plot the progress\n",
    "                if batch_i%100 == 0:\n",
    "                    print (\"[%d] [%d/%d] time: %s, [d_loss: %f, g_loss: %f]\" % (epoch, batch_i,\n",
    "                                                                            n_batches,\n",
    "                                                                            elapsed_time,\n",
    "                                                                            d_loss[0], g_loss[0]))\n",
    "                # If at save interval => save generated image samples\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    sample_images(dataset_name,epoch, batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def sample_images(dataset_name,epoch, batch_i):\n",
    "        os.makedirs('images/%s' % dataset_name, exist_ok=True)\n",
    "        r, c = 2, 3\n",
    "        imgs_A = load_data(dataset_name,domain=\"A\",batch_size=1, is_val=True)\n",
    "        imgs_B = load_data(dataset_name,domain=\"B\",batch_size=1, is_val=True)\n",
    "        # Translate images to the other domain\n",
    "        fake_B = g_AB.predict(imgs_A)\n",
    "        fake_A = g_BA.predict(imgs_B)\n",
    "        # Translate back to original domain\n",
    "        reconstr_A = g_BA.predict(fake_B)\n",
    "        reconstr_B = g_AB.predict(fake_A)\n",
    "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        titles = ['Original', 'Translated', 'Reconstructed']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[j])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%s/%d_%d.png\" % (dataset_name, epoch, batch_i))\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_rows = 128\n",
    "img_cols = 128\n",
    "channels = 3\n",
    "img_shape = (img_rows,img_cols,channels)\n",
    "\n",
    "patch = int(img_rows/ 2**4)\n",
    "disc_patch = (patch,patch,1)\n",
    "\n",
    "gf = 64\n",
    "df = 64\n",
    "optimizer = Adam(0.0002,0.5)\n",
    "#discriminator\n",
    "d_A = build_discriminator()\n",
    "d_B = build_discriminator()\n",
    "d_A.compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
    "d_B.compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
    "#two generators : input from both domains\n",
    "g_AB = build_generator()\n",
    "g_BA = build_generator()\n",
    "img_A = Input(shape =img_shape)\n",
    "img_B = Input(shape =img_shape)\n",
    "#translate one to other domain\n",
    "fake_B = g_AB(img_A)\n",
    "fake_A = g_BA(img_B)\n",
    "#translate back from fake AB\n",
    "reconstr_A = g_BA(fake_B)\n",
    "reconstr_B = g_AB(fake_A)\n",
    "#set discriminators untrainable\n",
    "d_A.trainable = False\n",
    "d_B.trainable = False\n",
    "#determine validity\n",
    "valid_A = d_A(fake_A)\n",
    "valid_B = d_B(fake_B)\n",
    "combined = Model(inputs=[img_A,img_B],\n",
    "                outputs=[valid_A,valid_B,fake_B,fake_A,reconstr_A,reconstr_B])\n",
    "combined.compile(loss=['mse','mse','mae','mae','mae','mae'],optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\"apple2orange\",epochs=20, batch_size=1, sample_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\"apple2orange\",epochs=10, batch_size=2, sample_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\"apple2orange\",epochs=10, batch_size=4, sample_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\"monet2photo\",epochs=10, batch_size=1, sample_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\"vangogh2photo\",epochs=10, batch_size=1, sample_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\"ukiyoe2photo\",epochs=10, batch_size=1, sample_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\"cezanne2photo\",epochs=10, batch_size=1, sample_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\"summer2winter\",epochs=10, batch_size=1, sample_interval=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
